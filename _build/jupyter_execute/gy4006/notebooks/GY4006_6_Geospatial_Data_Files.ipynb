{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446bd4f7-a01c-44b4-a519-5642417dc360",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bamacgabhann/GY4006/blob/main/gy4006/notebooks/GY4006_6_Geospatial_Data_Files.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f2e74-5153-4867-b248-b973c1a3c6f4",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/bamacgabhann/GY4006/main/gy4006/assets/images/GY4006_logo_1.png\" align=center alt=\"UL Geography logo\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3b3d9-f7e8-474b-ad92-ff4f469c627a",
   "metadata": {
    "id": "j-2xUUAfX0xa"
   },
   "source": [
    "# Creating and Using Geospatial Data Files\n",
    "\n",
    "So now we know that geospatial data can be in the form of dataframes containing coordinates with associated attributes, and we know how to use different kinds of coordinates. We're almost ready to use real geospatial data.\n",
    "\n",
    "But how do we get our real geospatial data into whatever tool we're using? How do we save geospatial data to a file? \n",
    "\n",
    "Word documents use ```.docx``` files, but not all word processors do, OpenOffice uses ```.odx``` files for example. Is geospatial data like that, with different programs having different ways of saving files? Can some software only open certain files?\n",
    "\n",
    "Well, it's both simpler and more complicated than that, but the good news is that most geospatial tools will be able to read most forms of geospatial data files. \n",
    "\n",
    "The less good news is that there's a few different formats you should get familiar with. I'll discuss 5 different vector geospatial formats here in particular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279363f-83af-4664-a461-e4fd4ae62128",
   "metadata": {},
   "source": [
    "## 1. CSV - Comma Separated Values\n",
    "\n",
    "CSV files are very simple. Each row of the data is on a different line, with the values for different columns separated by commas. Let's demonstrate using the air pollution data from the Attribute Data notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d77e65b-4d0e-4bf6-bee6-8c454c97ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea29991d-8bd2-4029-a121-91fb5311e97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-01 08:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1012</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01 08:00:30</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1012</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01 08:01:00</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1012</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01 08:01:30</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1013</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01 08:02:00</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1013</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PM2.5  PM10  Pressure  Temperature  Humidity  \\\n",
       "timestamp                                                           \n",
       "2023-11-01 08:00:00      3     5      1012           12        86   \n",
       "2023-11-01 08:00:30      4     6      1012           12        86   \n",
       "2023-11-01 08:01:00      6     5      1012           13        87   \n",
       "2023-11-01 08:01:30      2     3      1013           13        87   \n",
       "2023-11-01 08:02:00      3     4      1013           13        87   \n",
       "\n",
       "                                  geometry  \n",
       "timestamp                                   \n",
       "2023-11-01 08:00:00  POINT (555173 654321)  \n",
       "2023-11-01 08:00:30  POINT (555173 654321)  \n",
       "2023-11-01 08:01:00  POINT (555173 654321)  \n",
       "2023-11-01 08:01:30  POINT (555173 654321)  \n",
       "2023-11-01 08:02:00  POINT (555173 654321)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gpd.GeoDataFrame(\n",
    "    {\n",
    "        \"Measurement_time\": [\n",
    "            \"2023-11-01 08:00:00\",\n",
    "            \"2023-11-01 08:00:30\",\n",
    "            \"2023-11-01 08:01:00\",\n",
    "            \"2023-11-01 08:01:30\",\n",
    "            \"2023-11-01 08:02:00\",\n",
    "        ],\n",
    "        \"PM2.5\": [3, 4, 6, 2, 3],\n",
    "        \"PM10\": [5, 6, 5, 3, 4],\n",
    "        \"Pressure\": [1012, 1012, 1012, 1013, 1013],\n",
    "        \"Temperature\": [12, 12, 13, 13, 13],\n",
    "        \"Humidity\": [86, 86, 87, 87, 87],\n",
    "        \"geometry\": [Point(555173, 654321), Point(555173, 654321), Point(555173, 654321), Point(555173, 654321), Point(555173, 654321)],\n",
    "    }\n",
    ")\n",
    "gdf['timestamp'] = pd.to_datetime(gdf['Measurement_time'])\n",
    "gdf = gdf.set_index('timestamp')\n",
    "gdf = gdf.drop(columns=\"Measurement_time\")\n",
    "gdf = gdf.set_crs('epsg:2157')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5ef101-d466-4f9d-b128-722bfefd3ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:2157\n"
     ]
    }
   ],
   "source": [
    "print(gdf.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa1f17-7e67-426c-889d-2b8ddb40fd96",
   "metadata": {},
   "source": [
    "We can save this as a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68452b83-a204-4fed-9d39-732a00a24974",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_csv('../sample_data/ap.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f401a21-a790-42d9-9e1d-778142d5659a",
   "metadata": {},
   "source": [
    "and then look at what the contents of the file look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a751f17-2360-44e5-b621-c507ffe4fb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,PM2.5,PM10,Pressure,Temperature,Humidity,geometry\n",
      "2023-11-01 08:00:00,3,5,1012,12,86,POINT (555173 654321)\n",
      "2023-11-01 08:00:30,4,6,1012,12,86,POINT (555173 654321)\n",
      "2023-11-01 08:01:00,6,5,1012,13,87,POINT (555173 654321)\n",
      "2023-11-01 08:01:30,2,3,1013,13,87,POINT (555173 654321)\n",
      "2023-11-01 08:02:00,3,4,1013,13,87,POINT (555173 654321)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../sample_data/ap.csv', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "print (content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22061464-18f0-4dd4-bb9b-bc0c9c085bce",
   "metadata": {},
   "source": [
    "It's very simple and straightforward. Because of this, you'll find a lot of geospatial data saved as CSV files.\n",
    "\n",
    "However - the CSV format wasn't designed for geospatial data, and one thing it doesn't do is save any information about the coordinate reference system. That has to be manually managed if you're using CSVs. Which is often fine - but there are other formats which do save the CRS (and other associated information)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c17dc-9159-415c-9476-8c03a704fda3",
   "metadata": {},
   "source": [
    "## 2. ESRI Shapefiles\n",
    "\n",
    "Probably the most common geospatial data format is the ESRI shapefile. Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dfda5ca-eb7a-4ace-9fe1-96482f5cd49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24603/508446976.py:1: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file('../sample_data/ap.shp')\n",
      "/home/breandan/.pyenv/versions/3.11.6/envs/GY4006/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Field timestamp create as date field, though DateTime requested.\n",
      "  ogr_write(\n",
      "/home/breandan/.pyenv/versions/3.11.6/envs/GY4006/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Temperature' to 'Temperatur'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "gdf.to_file('../sample_data/ap.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020147d0-797b-48b8-bff7-b70f0d3005fc",
   "metadata": {},
   "source": [
    "Whoops. Okay, well, straight away we can see a disadvantage of the shapefile format. Let's change the datetime data to text, and try that again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7d130e-face-4827-bb68-cd2e0f9863c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01 08:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1012</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-01 08:00:30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1012</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-01 08:01:00</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1012</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-01 08:01:30</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1013</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-01 08:02:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1013</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  PM2.5  PM10  Pressure  Temperature  Humidity  \\\n",
       "0  2023-11-01 08:00:00      3     5      1012           12        86   \n",
       "1  2023-11-01 08:00:30      4     6      1012           12        86   \n",
       "2  2023-11-01 08:01:00      6     5      1012           13        87   \n",
       "3  2023-11-01 08:01:30      2     3      1013           13        87   \n",
       "4  2023-11-01 08:02:00      3     4      1013           13        87   \n",
       "\n",
       "                geometry  \n",
       "0  POINT (555173 654321)  \n",
       "1  POINT (555173 654321)  \n",
       "2  POINT (555173 654321)  \n",
       "3  POINT (555173 654321)  \n",
       "4  POINT (555173 654321)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_shp = gdf.reset_index()\n",
    "gdf_shp['timestamp'] = gdf_shp['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "gdf_shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fbc4b04-5298-4e8b-aff6-9c7126ca56d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24603/612289223.py:1: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf_shp.to_file('../sample_data/ap.shp')\n",
      "/home/breandan/.pyenv/versions/3.11.6/envs/GY4006/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Temperature' to 'Temperatur'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "gdf_shp.to_file('../sample_data/ap.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e153c8-4ee3-423a-986e-8e871d3bf612",
   "metadata": {},
   "source": [
    "Well, the warning there is giving us another limitation of the format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b41b76c6-0752-42ae-8cd7-8af4245c3818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Temperatur</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01 08:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1012</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-01 08:00:30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1012</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-01 08:01:00</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1012</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-01 08:01:30</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1013</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-01 08:02:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1013</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>POINT (555173 654321)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  PM2.5  PM10  Pressure  Temperatur  Humidity  \\\n",
       "0  2023-11-01 08:00:00      3     5      1012          12        86   \n",
       "1  2023-11-01 08:00:30      4     6      1012          12        86   \n",
       "2  2023-11-01 08:01:00      6     5      1012          13        87   \n",
       "3  2023-11-01 08:01:30      2     3      1013          13        87   \n",
       "4  2023-11-01 08:02:00      3     4      1013          13        87   \n",
       "\n",
       "                geometry  \n",
       "0  POINT (555173 654321)  \n",
       "1  POINT (555173 654321)  \n",
       "2  POINT (555173 654321)  \n",
       "3  POINT (555173 654321)  \n",
       "4  POINT (555173 654321)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_from_shp = gpd.read_file('../sample_data/ap.shp')\n",
    "gdf_from_shp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b55e4-90e9-48e8-b35a-d891a8857eda",
   "metadata": {},
   "source": [
    "I guess we just lost the 'e' at the end of 'Temperatur', so it could be worse, but that could be very irritating.\n",
    "\n",
    "Now, I can't show you the inside of a shapefile in the same way that I could with a CSV, because there's a fundamental difference here. CSVs are text files - whatever you type in, that's how it's saved. But shapefiles are a *binary* format - the data is saved as the binary representation rather than the straight text representation. I can show you the contents translated from binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c8f2742-ae5e-4aed-bfe3-1c3bd151278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"\\x00\\x00'\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00x\\xe8\\x03\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00J\\xf1 A\\x00\\x00\\x00\\x00\\xe2\\xf7#A\\x00\\x00\\x00\\x00J\\xf1 A\\x00\\x00\\x00\\x00\\xe2\\xf7#A\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\n\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00J\\xf1 A\\x00\\x00\\x00\\x00\\xe2\\xf7#A\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\n\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00J\\xf1 A\\x00\\x00\\x00\\x00\\xe2\\xf7#A\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\n\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00J\\xf1 A\\x00\\x00\\x00\\x00\\xe2\\xf7#A\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\n\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00J\\xf1 A\\x00\\x00\\x00\\x00\\xe2\\xf7#A\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\n\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00J\\xf1 A\\x00\\x00\\x00\\x00\\xe2\\xf7#A\"\n"
     ]
    }
   ],
   "source": [
    "with open('../sample_data/ap.shp', 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "print (content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4fb1ee-b63e-4bbe-ac9a-96932fe9376d",
   "metadata": {},
   "source": [
    "Not really all that informative, to be honest. \n",
    "\n",
    "Now, there is another issue with shapefiles as well. If you look into the ```sample_data``` folder where it was saved, you'll also see files called ```ap.cpg```, ```ap.dbf```, and ```ap.shx```. We didn't ask to create any of those - but they are created with a shapefile.\n",
    "\n",
    "The reason for this is ultimately the same as the 10-character limit for column names, and the lack of support for datetime columns. The shapefile format was created in the 1980s when GIS started. Computers in the 1980s were far less powerful than modern computers, and so, over time as more was possible in GIS, more data was needed to be saved than the original shapefile format allowed. Rather than changing to a new format, the format was simply extended to save the additional information in these *sidecar* files. \n",
    "\n",
    "All of this is very irritating. True, it's just a minor irritation, but every year since I started teaching GIS, I've had an issue where a student comes to me in a panic saying \"my map has stopped working, help!\". And when I go to help them, I see that their data folder has the ```.shp``` file, but none of the additional sidecar files. \"Oh\", will say the student, \"I noticed all those extra files in the folder and I wanted to tidy it up, so I deleted them all\". \n",
    "\n",
    "Every year. Anyway, don't do that. Or even better, just don't use shapefiles.\n",
    "\n",
    "Even all these minor irritations aren't the main reason not to use shapfiles. The main reason not to use the format is that it's horribly slow and memory inefficient. There are formats which take up less space, and are literally hundreds of times faster than shapefiles. The amount of compute time across the world wasted due to reading and writing shapefiles probably accounts for a measurable amount of climate change. \n",
    "\n",
    "But somehow, despite all the limitations, it's still the default geospatial vector file format, so you're going to come across it a lot, unfortunately - especially if you're using ArcGIS Pro, because it's still ESRI's default format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6628e332-ced9-465c-8c73-5d2d8334dbac",
   "metadata": {},
   "source": [
    "## 3. GeoPackage and GeoDataBase\n",
    "\n",
    "The default file format in QGIS, geopackage files save geospatial data in a database format, using SQLite. Now, I'm not an expert in databases, but using a database format means the files are optimised for fast retrieval of data.\n",
    "\n",
    "Geopackage files are essentially the standard open source alternative to shapefiles, and are a vast improvement. They don't have a limitation on datetime fields, or the length of column names; and not only are there no sidecar files, you can actually save multiple data layers to a single geopackage file. We can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c73b67-dcc4-4eeb-ad07-87d49c3e949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('../sample_data/ap.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd32b544-2023-46cb-9198-9987c4b27078",
   "metadata": {},
   "source": [
    "and that works, which the shapefile version didn't until we'd made some changes - but if we also had data from another sensor, or map data for the area around the location, we could save it to the same file, with a different layer name. So, if you have multiple layers, rather than 4-6 files per layer with shapefiles, you could have one file for *all* of your layers. That's tidy.\n",
    "\n",
    "Geopackages are a bit slow though. They're an order of magnitude faster than shapefiles, but there are still faster new formats. \n",
    "\n",
    "GeoDataBase files are ESRI's database-format based files.\n",
    "\n",
    "Both QGIS and ArcGIS Pro can read both GeoPackage and GeoDataBase files, so there's no real concerns over data sharing with users using different formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca2b04-414e-4629-9f8e-45a554212c91",
   "metadata": {},
   "source": [
    "## 4. Feather and Parquet\n",
    "\n",
    "Without getting even further into computer science than I already have, it would be difficult to really explain just why these formats are so good. They're based around the Apache Arrow data format, and for now let's just say that it's an incredibly efficient binary format. The files are smaller, and they can be written and read literally hundreds of times faster than other formats. The Open Geospatial Consortium has defined geospatial versions, GeoFeather and GeoParquet, which is what GeoPandas is actually using when we run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "963ceee1-77f5-4189-b36d-1d15fec6677f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow.parquet'. pyarrow is required for Parquet support.  \"\n        \"Use pip or conda to install pyarrow.parquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../sample_data/ap.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m gdf\u001b[38;5;241m.\u001b[39mto_feather(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../sample_data/ap.feather\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/envs/GY4006/lib/python3.11/site-packages/geopandas/geodataframe.py:1377\u001b[0m, in \u001b[0;36mGeoDataFrame.to_parquet\u001b[0;34m(self, path, index, compression, geometry_encoding, write_covering_bbox, schema_version, **kwargs)\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoPandas only supports using pyarrow as the engine for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1372\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_parquet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m passed instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1373\u001b[0m     )\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_parquet\n\u001b[0;32m-> 1377\u001b[0m \u001b[43m_to_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_covering_bbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_covering_bbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/envs/GY4006/lib/python3.11/site-packages/geopandas/io/arrow.py:427\u001b[0m, in \u001b[0;36m_to_parquet\u001b[0;34m(df, path, index, compression, geometry_encoding, schema_version, write_covering_bbox, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_parquet\u001b[39m(\n\u001b[1;32m    380\u001b[0m     df,\n\u001b[1;32m    381\u001b[0m     path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    388\u001b[0m ):\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    Write a GeoDataFrame to the Parquet format.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m        Additional keyword arguments passed to pyarrow.parquet.write_table().\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m     parquet \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow is required for Parquet support.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     path \u001b[38;5;241m=\u001b[39m _expand_user(path)\n\u001b[1;32m    432\u001b[0m     table \u001b[38;5;241m=\u001b[39m _geopandas_to_arrow(\n\u001b[1;32m    433\u001b[0m         df,\n\u001b[1;32m    434\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    437\u001b[0m         write_covering_bbox\u001b[38;5;241m=\u001b[39mwrite_covering_bbox,\n\u001b[1;32m    438\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/envs/GY4006/lib/python3.11/site-packages/geopandas/_compat.py:64\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra)\u001b[0m\n\u001b[1;32m     61\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'pyarrow.parquet'. pyarrow is required for Parquet support.  \"\n        \"Use pip or conda to install pyarrow.parquet."
     ]
    }
   ],
   "source": [
    "gdf.to_parquet('../sample_data/ap.parquet')\n",
    "gdf.to_feather('../sample_data/ap.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c13f0-73d5-474a-9c5a-117e796f4e2c",
   "metadata": {},
   "source": [
    "So if we read them back in, it doesn't lose geospatial information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea74b252-7391-461f-899d-b4548f2d8d9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow.parquet'. pyarrow is required for Parquet support.  \"\n        \"Use pip or conda to install pyarrow.parquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gdf_p \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../sample_data/ap.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m gdf_p\u001b[38;5;241m.\u001b[39mcrs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/envs/GY4006/lib/python3.11/site-packages/geopandas/io/arrow.py:739\u001b[0m, in \u001b[0;36m_read_parquet\u001b[0;34m(path, columns, storage_options, bbox, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_parquet\u001b[39m(path, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, bbox\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;124;03m    Load a Parquet object from the file path, returning a GeoDataFrame.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;124;03m    ... )  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 739\u001b[0m     parquet \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow is required for Parquet support.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pyarrow_hotfix\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pandas-dev/pandas/pull/41194): see if pandas\u001b[39;00m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;66;03m# adds filesystem as a keyword and match that.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/envs/GY4006/lib/python3.11/site-packages/geopandas/_compat.py:64\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra)\u001b[0m\n\u001b[1;32m     61\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'pyarrow.parquet'. pyarrow is required for Parquet support.  \"\n        \"Use pip or conda to install pyarrow.parquet."
     ]
    }
   ],
   "source": [
    "gdf_p = gpd.read_parquet('../sample_data/ap.parquet')\n",
    "gdf_p.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "367de475-712a-42ea-821c-07899e019ceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow.feather'. pyarrow is required for Feather support.  \"\n        \"Use pip or conda to install pyarrow.feather.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gdf_f \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../sample_data/ap.feather\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m gdf_f\u001b[38;5;241m.\u001b[39mcrs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/envs/GY4006/lib/python3.11/site-packages/geopandas/io/arrow.py:834\u001b[0m, in \u001b[0;36m_read_feather\u001b[0;34m(path, columns, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_feather\u001b[39m(path, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    783\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;124;03m    Load a Feather object from the file path, returning a GeoDataFrame.\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;124;03m    ... )  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 834\u001b[0m     feather \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow.feather\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow is required for Feather support.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;66;03m# TODO move this into `import_optional_dependency`\u001b[39;00m\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/envs/GY4006/lib/python3.11/site-packages/geopandas/_compat.py:64\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra)\u001b[0m\n\u001b[1;32m     61\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'pyarrow.feather'. pyarrow is required for Feather support.  \"\n        \"Use pip or conda to install pyarrow.feather."
     ]
    }
   ],
   "source": [
    "gdf_f = gpd.read_feather('../sample_data/ap.feather')\n",
    "gdf_f.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26997912-b8bd-4d0c-8d9b-f29aefb865f9",
   "metadata": {},
   "source": [
    "These formats are very, very new, so they're not enormously widespread yet, and they are still being developed fully. But if you might do more than occasionally play with geospatial data, it's very worth being aware of them - and expect to see them becoming a lot more common in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ecfb87-a7ca-41cb-9b00-227eea21a589",
   "metadata": {},
   "source": [
    "## 5. GeoJSON\n",
    "\n",
    "GeoJSON files are more or less the standard for geospatial data being transmitted over the internet - for example, sensor data. Or, if you've ever used a real-time public transport information app, the app was receiving data as a GeoJSON file to tell you how long you'd be waiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2554785-bc66-44f1-9e4c-12d36d8352b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('../sample_data/ap.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f74ca20-5cac-4bf1-a980-0f1cf7928d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"type\": \"FeatureCollection\",\n",
      "\"name\": \"ap\",\n",
      "\"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:EPSG::2157\" } },\n",
      "\"features\": [\n",
      "{ \"type\": \"Feature\", \"properties\": { \"timestamp\": \"2023-11-01T08:00:00\", \"PM2.5\": 3, \"PM10\": 5, \"Pressure\": 1012, \"Temperature\": 12, \"Humidity\": 86 }, \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 555173.0, 654321.0 ] } },\n",
      "{ \"type\": \"Feature\", \"properties\": { \"timestamp\": \"2023-11-01T08:00:30\", \"PM2.5\": 4, \"PM10\": 6, \"Pressure\": 1012, \"Temperature\": 12, \"Humidity\": 86 }, \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 555173.0, 654321.0 ] } },\n",
      "{ \"type\": \"Feature\", \"properties\": { \"timestamp\": \"2023-11-01T08:01:00\", \"PM2.5\": 6, \"PM10\": 5, \"Pressure\": 1012, \"Temperature\": 13, \"Humidity\": 87 }, \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 555173.0, 654321.0 ] } },\n",
      "{ \"type\": \"Feature\", \"properties\": { \"timestamp\": \"2023-11-01T08:01:30\", \"PM2.5\": 2, \"PM10\": 3, \"Pressure\": 1013, \"Temperature\": 13, \"Humidity\": 87 }, \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 555173.0, 654321.0 ] } },\n",
      "{ \"type\": \"Feature\", \"properties\": { \"timestamp\": \"2023-11-01T08:02:00\", \"PM2.5\": 3, \"PM10\": 4, \"Pressure\": 1013, \"Temperature\": 13, \"Humidity\": 87 }, \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 555173.0, 654321.0 ] } }\n",
      "]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../sample_data/ap.geojson', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "print (content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a91901-5833-4335-b311-4915c81c4c2c",
   "metadata": {},
   "source": [
    "As you can see there, the GeoJSON format is somewhat human readable. You can see each feature separately, and every piece of data for each feature is labelled.\n",
    "\n",
    "Of course, this would be a massive disadvantage in terms of file size. This is essentially like a CSV, but adding the relevant column header before every single piece of data. Even in this short example, you can see how often those are repeated.\n",
    "\n",
    "But this format isn't intended for storage of huge datasets. It's intended for sending short snippets of data in a format that a person can understand. You wouldn't want to be storing 5 million data points in this format - but it has its place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cb873d-8570-4aeb-970e-f122b2938b2c",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "Now that we've been introduced to the main geospatial vector data formats, we're ready to start looking at doing some geoprocessing of vector geospatial data. Next Notebook uses some real data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a45bc-064d-4645-a896-efc51965d539",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "GY4006 Notebooks in Colab: \n",
    "\n",
    "2. Data Types <a href=\"https://colab.research.google.com/github/bamacgabhann/GY4006/blob/main/gy4006/notebooks/GY4006_2_Data_Types.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "3. Vector Data <a href=\"https://colab.research.google.com/github/bamacgabhann/GY4006/blob/main/gy4006/notebooks/GY4006_3_Vector_Data.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "4. Attribute Data <a href=\"https://colab.research.google.com/github/bamacgabhann/GY4006/blob/main/gy4006/notebooks/GY4006_4_Attribute_Data.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "5. Coordinate Reference Systems <a href=\"https://colab.research.google.com/github/bamacgabhann/GY4006/blob/main/gy4006/notebooks/GY4006_5_Coordinate_Reference_Systems.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "6. Geospatial Data Files <a href=\"https://colab.research.google.com/github/bamacgabhann/GY4006/blob/main/gy4006/notebooks/GY4006_6_Geospatial_Data_Files.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "7. Vector Geoprocessing <a href=\"https://colab.research.google.com/github/bamacgabhann/GY4006/blob/main/gy4006/notebooks/GY4006_7_Vector_Geoprocessing.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "8. Introduction to Raster Data <a href=\"https://colab.research.google.com/github/bamacgabhann/GY4006/blob/main/gy4006/notebooks/GY4006_8_Introduction_To_Raster_Data.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> \n",
    "\n",
    "9. Single-band Raster Data <a href=\"https://colab.research.google.com/github/bamacgabhann/GY4006/blob/main/gy4006/notebooks/GY4006_9_Single-band_Raster_Data.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "10. Multi-band Raster Data: Passive Remote Sensing <a href=\"https://colab.research.google.com/github/bamacgabhann/GY4006/blob/main/gy4006/notebooks/GY4006_10_Multi-band_Raster_Data-Passive_Remote_Sensing.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}